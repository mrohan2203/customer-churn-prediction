{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSm-7HmZAESI",
        "outputId": "fdc367d1-dbe8-47e7-a0a8-7d9234feb958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "metadata": {
        "id": "DnRgKIrZAngD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Spark Session\n",
        "spark = SparkSession.builder.appName(\"ChurnPrediction\").getOrCreate()"
      ],
      "metadata": {
        "id": "7dejsaEyAq7c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load Data\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/Colab Notebooks/telco_customer_churn.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "QtaWfCUUAtfH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Data Cleaning\n",
        "df = df.dropna()\n",
        "df = df.drop(\"customerID\")"
      ],
      "metadata": {
        "id": "N1kGHSYqAxhp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Encode Categorical Columns\n",
        "categorical_cols = [field for (field, dtype) in df.dtypes if dtype == \"string\" and field != \"Churn\"]\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_Index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=col+\"_Index\", outputCol=col+\"_Vec\") for col in categorical_cols]"
      ],
      "metadata": {
        "id": "TDYCjraWA5nn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Label Indexing\n",
        "label_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")"
      ],
      "metadata": {
        "id": "piOqWpdQA73l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Assemble Features\n",
        "numeric_cols = [field for (field, dtype) in df.dtypes if dtype in [\"double\", \"int\"] and field != \"Churn\"]\n",
        "assembler_inputs = [col + \"_Vec\" for col in categorical_cols] + numeric_cols\n",
        "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"assembled_features\")\n",
        "scaler = StandardScaler(inputCol=\"assembled_features\", outputCol=\"features\")"
      ],
      "metadata": {
        "id": "wtXfWtLcA-_P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "mEUnZvqIBBMJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8. Pipeline\n",
        "stages = indexers + encoders + [label_indexer, assembler, scaler, rf]\n",
        "pipeline = Pipeline(stages=stages)"
      ],
      "metadata": {
        "id": "FH2YPbF4BFP0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Train/Test Split\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "H2CS36h4BHWu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Cross-Validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [20, 50]).build()\n",
        "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)"
      ],
      "metadata": {
        "id": "x52_ZVnkBiGZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Fit Model\n",
        "cv_model = cv.fit(train_data)"
      ],
      "metadata": {
        "id": "oB7D0aFEBkD2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Evaluate\n",
        "predictions = cv_model.transform(test_data)\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC on test data: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMJH3a5yBodn",
        "outputId": "daae8ece-854f-42b5-a1b5-f86b8f7daa76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC on test data: 0.8235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Save Model (optional)\n",
        "cv_model.write().overwrite().save(\"churn_model\")"
      ],
      "metadata": {
        "id": "zl3GwXnGCLfA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5-fNs16CSTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}